{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DistortedTextPytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartika-nair/CAPTCHA-Solver/blob/master/DistortedTextPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCPt2IrzfN3D"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "import string\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import multiprocessing as mp\n",
        "\n",
        "import cv2\n",
        "import imutils\n",
        "import tqdm as tq\n",
        "import pickle\n",
        "import os.path\n",
        "from imutils import paths\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Flatten, Dense\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2oH5CV5cvrK",
        "outputId": "57c1111a-3aa6-4c63-9a95-cfdf224de147"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKKH7J6mEQmC"
      },
      "source": [
        "**PROJECT DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60Aan6iuQcZL"
      },
      "source": [
        "cpu_count = mp.cpu_count()\n",
        "\n",
        "IMAGES_FOLDER = \"/content/drive/MyDrive/Colab Notebooks/DistortedText/Pytorch/Images\"\n",
        "\n",
        "EXTRACT_IMAGES = 0 #SET THIS TO TRUE TO GENERATE IMAGES READBLE BY CODE\n",
        "NUMBER_OF_LETTERS = 4\n",
        "\n",
        "EXTRACTED_FOLDER = \"/content/drive/MyDrive/Colab Notebooks/DistortedText/Pytorch/EXTRACTED\"\n",
        "\n",
        "IMAGE_SIZE = 32\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYY3_1PSETrJ"
      },
      "source": [
        "**EXTRACT IMAGES FROM CAPTCHA IMAGES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOhWxyOFQ-uy"
      },
      "source": [
        "def extract_image(path = IMAGES_FOLDER, output = EXTRACTED_FOLDER):\n",
        "    captcha_image_files = glob.glob(os.path.join(path, \"*\"))\n",
        "    counts = {}\n",
        "    for (i, captcha_image_file) in tq.tqdm(enumerate(captcha_image_files)):\n",
        "        # print(f\"[DEBUG]{i}: {os.path.basename(captcha_image_file)}\")\n",
        "\n",
        "        try:\n",
        "            filename = os.path.basename(captcha_image_file)\n",
        "            captcha_correct_text = os.path.splitext(filename)[0]\n",
        "\n",
        "            image = cv2.imread(captcha_image_file)\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            gray = cv2.copyMakeBorder(gray, 8, 8, 8, 8, cv2.BORDER_REPLICATE)\n",
        "\n",
        "            thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "            contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "            contours = contours[1] if imutils.is_cv3() else contours[0]\n",
        "\n",
        "            letter_image_regions = []\n",
        "\n",
        "            for contour in contours:\n",
        "                (x, y, w, h) = cv2.boundingRect(contour)\n",
        "\n",
        "                if w / h > 1.25:\n",
        "\n",
        "                    half_width = int(w / 2)\n",
        "                    letter_image_regions.append((x, y, half_width, h))\n",
        "                    letter_image_regions.append((x + half_width, y, half_width, h))\n",
        "\n",
        "                else:\n",
        "\n",
        "                    letter_image_regions.append((x, y, w, h))\n",
        "\n",
        "            if len(letter_image_regions) != NUMBER_OF_LETTERS:\n",
        "                continue\n",
        "\n",
        "            letter_image_regions = sorted(letter_image_regions, key=lambda x: x[0])\n",
        "\n",
        "            for letter_bounding_box, letter_text in zip(letter_image_regions, captcha_correct_text):\n",
        "                x, y, w, h = letter_bounding_box\n",
        "                letter_image = gray[y - 2:y + h + 2, x - 2:x + w + 2]\n",
        "\n",
        "                save_path = os.path.join(output, \"\")\n",
        "\n",
        "            if not os.path.exists(save_path):\n",
        "                os.makedirs(save_path)\n",
        "\n",
        "            count = counts.get(letter_text, 1)\n",
        "            p = os.path.join(save_path, \"{}_{}.png\".format(letter_text, str(count).zfill(6)))\n",
        "            cv2.imwrite(p, letter_image)\n",
        "\n",
        "            counts[letter_text] = count + 1\n",
        "        except Exception as e:\n",
        "            pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljsgP8rVzPfR"
      },
      "source": [
        "if EXTRACT_IMAGES:\n",
        "    extract_image()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQNbzGYMzZC3"
      },
      "source": [
        "def resize_to_fit(image, width = IMAGE_SIZE, height = IMAGE_SIZE):\n",
        "\n",
        "    (h, w) = image.shape[:2]\n",
        "\n",
        "    if w > h:\n",
        "        image = imutils.resize(image, width=width)\n",
        "    else:\n",
        "        image = imutils.resize(image, height=height)\n",
        "\n",
        "    padW = int((width - image.shape[1]) / 2.0)\n",
        "    padH = int((height - image.shape[0]) / 2.0)\n",
        "\n",
        "    image = cv2.copyMakeBorder(image, padH, padH, padW, padW,\n",
        "        cv2.BORDER_REPLICATE)\n",
        "    image = cv2.resize(image, (width, height))\n",
        "\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YXsK8G5EY66"
      },
      "source": [
        "**CUSTOM DATASET CLASS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoOijxPDzolD"
      },
      "source": [
        "class CAPTCHADataset(Dataset):\n",
        "\n",
        "    def __init__(self, images, data_dir = EXTRACTED_FOLDER):\n",
        "        self.data_dir = data_dir\n",
        "        self.images = images\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image_fn = self.images[index]\n",
        "        image = cv2.imread(f\"{self.data_dir}/{image_fn}\")\n",
        "        # image = Image.open(image_fp).convert('RGB')\n",
        "        image = resize_to_fit(image)\n",
        "        image = self.transform(image)\n",
        "        text = image_fn.split(\"_\")[0]\n",
        "        return image, text\n",
        "    \n",
        "    def transform(self, image):\n",
        "        \n",
        "        transform_ops = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "        ])\n",
        "        return transform_ops(image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pNofuicEeMU"
      },
      "source": [
        "**ENCODE DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYCjwAM_BjEX"
      },
      "source": [
        "images = os.listdir(EXTRACTED_FOLDER)\n",
        "image_fns_train, image_fns_test = train_test_split(images, random_state=0)\n",
        "image_ns = [image.split(\"_\")[0] for image in images]\n",
        "image_ns = \"\".join(image_ns)\n",
        "letters = sorted(list(set(list(image_ns))))\n",
        "vocabulary = [\"-\"] + letters\n",
        "idx2char = {k:v for k,v in enumerate(vocabulary, start=0)}\n",
        "char2idx = {v:k for k,v in idx2char.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZpHnJP_GdcJ"
      },
      "source": [
        "**MODEL PARAMETERS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czE0ieDGGTU-"
      },
      "source": [
        "batch_size = 6\n",
        "num_epochs = 50\n",
        "lr = 0.001\n",
        "log_interval = 100\n",
        "gamma = 0.7\n",
        "num_chars = len(char2idx)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsQzFjj6GhzU"
      },
      "source": [
        "**DEFINE TEST AND TRAIN LOADER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdUrebylE3-w"
      },
      "source": [
        "trainset = CAPTCHADataset(images = image_fns_train, data_dir =  EXTRACTED_FOLDER) \n",
        "testset = CAPTCHADataset(images = image_fns_test, data_dir = EXTRACTED_FOLDER)\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, num_workers=cpu_count, shuffle=True)\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, num_workers=cpu_count, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGkFvwxiGa0I"
      },
      "source": [
        "image_batch, text_batch = iter(train_loader).next()\n",
        "num_chars = len(char2idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spLJ48NoZbOL"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(12544, 128)\n",
        "        self.fc2 = nn.Linear(128, 32)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-hhZWz9iXlW",
        "outputId": "da3410bb-40df-4721-e0a6-77c3ee2cbdc3"
      },
      "source": [
        "modelTest = Net()\n",
        "modelTest(image_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.5127, -3.6010, -3.1507, -3.5474, -3.4267, -3.3147, -3.2178, -3.3107,\n",
              "         -3.3685, -3.5525, -3.4175, -3.4722, -3.6291, -3.4764, -3.4547, -3.3513,\n",
              "         -3.3436, -3.3090, -3.7825, -3.5965, -3.6585, -3.7621, -3.4247, -3.6718,\n",
              "         -3.2866, -3.5469, -3.4015, -3.5309, -3.5189, -3.4720, -3.4733, -3.6763],\n",
              "        [-3.5990, -3.3793, -3.4121, -3.3929, -3.7313, -3.6481, -3.3620, -3.2458,\n",
              "         -3.4808, -3.2707, -3.3491, -3.5272, -3.5792, -3.7399, -3.3155, -3.2990,\n",
              "         -3.4335, -3.2495, -3.6324, -3.4623, -3.5613, -3.6476, -3.2703, -3.3847,\n",
              "         -3.5120, -3.6429, -3.6646, -3.5096, -3.6509, -3.4801, -3.2837, -3.5329],\n",
              "        [-3.5521, -3.4682, -3.1800, -3.6213, -3.6790, -3.3756, -3.4565, -3.4056,\n",
              "         -3.6410, -3.4283, -3.4397, -3.2539, -3.7661, -3.5775, -3.3626, -3.5180,\n",
              "         -3.3721, -3.1818, -3.6121, -3.5299, -3.6634, -3.5630, -3.2958, -3.6680,\n",
              "         -3.3834, -3.4428, -3.4298, -3.3764, -3.6941, -3.5135, -3.4508, -3.3424],\n",
              "        [-3.6230, -3.4442, -3.4243, -3.6035, -3.5821, -3.4964, -3.4083, -3.3104,\n",
              "         -3.7603, -3.2484, -3.6490, -3.2815, -3.4140, -3.4749, -3.4507, -3.4246,\n",
              "         -3.4172, -3.4796, -3.4712, -3.6124, -3.4774, -3.5103, -3.2793, -3.5471,\n",
              "         -3.3682, -3.3572, -3.5567, -3.4528, -3.4375, -3.6922, -3.3442, -3.5323],\n",
              "        [-3.5820, -3.4634, -3.3742, -3.5227, -3.5754, -3.3903, -3.5558, -3.3426,\n",
              "         -3.5329, -3.3872, -3.5029, -3.4166, -3.5354, -3.5943, -3.4821, -3.4265,\n",
              "         -3.3800, -3.3241, -3.4841, -3.5014, -3.3788, -3.7353, -3.2659, -3.6945,\n",
              "         -3.3918, -3.4264, -3.4255, -3.4958, -3.3581, -3.5111, -3.4892, -3.5202],\n",
              "        [-3.6595, -3.4581, -3.4433, -3.4185, -3.5444, -3.4258, -3.4885, -3.3368,\n",
              "         -3.4687, -3.4146, -3.6636, -3.3747, -3.7635, -3.3156, -3.5730, -3.3378,\n",
              "         -3.3182, -3.5199, -3.6435, -3.4143, -3.4485, -3.7569, -3.3692, -3.4967,\n",
              "         -3.2229, -3.4935, -3.2169, -3.5583, -3.2685, -3.6844, -3.4502, -3.6866]],\n",
              "       grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb9zyqxcZbis"
      },
      "source": [
        "model = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDcwPgfTeCmX"
      },
      "source": [
        "def encode_text_batch(text_batch, device):\n",
        "    \n",
        "    text_batch_targets_lens = [len(text) for text in text_batch]\n",
        "    text_batch_targets_lens = torch.LongTensor(text_batch_targets_lens)\n",
        "    \n",
        "    text_batch_concat = \"\".join(text_batch)\n",
        "    text_batch_targets = [char2idx[c] for c in text_batch_concat]\n",
        "    text_batch_targets = torch.LongTensor(text_batch_targets)\n",
        "    \n",
        "    return text_batch_targets.to(device), text_batch_targets_lens.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS0Sur4UZ2wg"
      },
      "source": [
        "optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2mDBCdvgroa"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwmtkQFIe-RE"
      },
      "source": [
        "def train(epoch, train_loader = train_loader, device = device, log_interval = log_interval, model = model):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        target, _ = encode_text_batch(text_batch, device)\n",
        "        if (data.size()[0] != batch_size or (target.size()[0] >= num_chars or target.size()[0] <= 0)):\n",
        "            continue\n",
        "        loss = loss_func(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({round(100. * batch_idx / len(train_loader), 2)}%)]\\tLoss: {round(loss.item(), 6)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67JKkaRGffNu"
      },
      "source": [
        "def test(model = model, device = device, test_loader = test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target\n",
        "            target, _ = encode_text_batch(text_batch, device)\n",
        "            if (data.size()[0] != batch_size or (target.size()[0] >= num_chars or target.size()[0] <= 0)):\n",
        "                continue\n",
        "            output = model(data)\n",
        "            test_loss += loss_func(output, target).item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJz6aQjwZjEy",
        "outputId": "4b416064-cf22-4603-c335-d1c7f4a8a5db"
      },
      "source": [
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/7264 (0.0%)]\tLoss: 3.511806\n",
            "Train Epoch: 1 [600/7264 (8.26%)]\tLoss: 3.218011\n",
            "Train Epoch: 1 [1200/7264 (16.52%)]\tLoss: 2.897994\n",
            "Train Epoch: 1 [1800/7264 (24.77%)]\tLoss: 2.255287\n",
            "Train Epoch: 1 [2400/7264 (33.03%)]\tLoss: 2.159617\n",
            "Train Epoch: 1 [3000/7264 (41.29%)]\tLoss: 1.834369\n",
            "Train Epoch: 1 [3600/7264 (49.55%)]\tLoss: 1.772397\n",
            "Train Epoch: 1 [4200/7264 (57.8%)]\tLoss: 1.897608\n",
            "Train Epoch: 1 [4800/7264 (66.06%)]\tLoss: 2.221812\n",
            "Train Epoch: 1 [5400/7264 (74.32%)]\tLoss: 2.273295\n",
            "Train Epoch: 1 [6000/7264 (82.58%)]\tLoss: 2.074849\n",
            "Train Epoch: 1 [6600/7264 (90.83%)]\tLoss: 2.128443\n",
            "Train Epoch: 1 [7200/7264 (99.09%)]\tLoss: 1.568285\n",
            "\n",
            "Test set: Average loss: 0.2766, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 2 [0/7264 (0.0%)]\tLoss: 1.587813\n",
            "Train Epoch: 2 [600/7264 (8.26%)]\tLoss: 2.364811\n",
            "Train Epoch: 2 [1200/7264 (16.52%)]\tLoss: 1.884482\n",
            "Train Epoch: 2 [1800/7264 (24.77%)]\tLoss: 2.165469\n",
            "Train Epoch: 2 [2400/7264 (33.03%)]\tLoss: 1.343225\n",
            "Train Epoch: 2 [3000/7264 (41.29%)]\tLoss: 2.159303\n",
            "Train Epoch: 2 [3600/7264 (49.55%)]\tLoss: 2.143686\n",
            "Train Epoch: 2 [4200/7264 (57.8%)]\tLoss: 2.135387\n",
            "Train Epoch: 2 [4800/7264 (66.06%)]\tLoss: 1.569055\n",
            "Train Epoch: 2 [5400/7264 (74.32%)]\tLoss: 2.122365\n",
            "Train Epoch: 2 [6000/7264 (82.58%)]\tLoss: 1.892829\n",
            "Train Epoch: 2 [6600/7264 (90.83%)]\tLoss: 1.801913\n",
            "Train Epoch: 2 [7200/7264 (99.09%)]\tLoss: 1.974029\n",
            "\n",
            "Test set: Average loss: 0.2714, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 3 [0/7264 (0.0%)]\tLoss: 1.922896\n",
            "Train Epoch: 3 [600/7264 (8.26%)]\tLoss: 1.397622\n",
            "Train Epoch: 3 [1200/7264 (16.52%)]\tLoss: 2.159989\n",
            "Train Epoch: 3 [1800/7264 (24.77%)]\tLoss: 1.501116\n",
            "Train Epoch: 3 [2400/7264 (33.03%)]\tLoss: 1.69514\n",
            "Train Epoch: 3 [3000/7264 (41.29%)]\tLoss: 2.014414\n",
            "Train Epoch: 3 [3600/7264 (49.55%)]\tLoss: 1.958478\n",
            "Train Epoch: 3 [4200/7264 (57.8%)]\tLoss: 1.684324\n",
            "Train Epoch: 3 [4800/7264 (66.06%)]\tLoss: 2.126084\n",
            "Train Epoch: 3 [5400/7264 (74.32%)]\tLoss: 2.134019\n",
            "Train Epoch: 3 [6000/7264 (82.58%)]\tLoss: 2.14664\n",
            "Train Epoch: 3 [6600/7264 (90.83%)]\tLoss: 1.456171\n",
            "Train Epoch: 3 [7200/7264 (99.09%)]\tLoss: 1.794358\n",
            "\n",
            "Test set: Average loss: 0.2686, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 4 [0/7264 (0.0%)]\tLoss: 1.556406\n",
            "Train Epoch: 4 [600/7264 (8.26%)]\tLoss: 1.714536\n",
            "Train Epoch: 4 [1200/7264 (16.52%)]\tLoss: 1.916378\n",
            "Train Epoch: 4 [1800/7264 (24.77%)]\tLoss: 1.674731\n",
            "Train Epoch: 4 [2400/7264 (33.03%)]\tLoss: 1.695268\n",
            "Train Epoch: 4 [3000/7264 (41.29%)]\tLoss: 1.865222\n",
            "Train Epoch: 4 [3600/7264 (49.55%)]\tLoss: 2.015478\n",
            "Train Epoch: 4 [4200/7264 (57.8%)]\tLoss: 1.775946\n",
            "Train Epoch: 4 [4800/7264 (66.06%)]\tLoss: 1.712981\n",
            "Train Epoch: 4 [5400/7264 (74.32%)]\tLoss: 1.766064\n",
            "Train Epoch: 4 [6000/7264 (82.58%)]\tLoss: 1.849031\n",
            "Train Epoch: 4 [6600/7264 (90.83%)]\tLoss: 2.057979\n",
            "Train Epoch: 4 [7200/7264 (99.09%)]\tLoss: 1.808252\n",
            "\n",
            "Test set: Average loss: 0.2682, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 5 [0/7264 (0.0%)]\tLoss: 1.610386\n",
            "Train Epoch: 5 [600/7264 (8.26%)]\tLoss: 1.958694\n",
            "Train Epoch: 5 [1200/7264 (16.52%)]\tLoss: 1.685443\n",
            "Train Epoch: 5 [1800/7264 (24.77%)]\tLoss: 1.82743\n",
            "Train Epoch: 5 [2400/7264 (33.03%)]\tLoss: 1.846196\n",
            "Train Epoch: 5 [3000/7264 (41.29%)]\tLoss: 2.177994\n",
            "Train Epoch: 5 [3600/7264 (49.55%)]\tLoss: 1.85595\n",
            "Train Epoch: 5 [4200/7264 (57.8%)]\tLoss: 1.635232\n",
            "Train Epoch: 5 [4800/7264 (66.06%)]\tLoss: 1.77782\n",
            "Train Epoch: 5 [5400/7264 (74.32%)]\tLoss: 2.029004\n",
            "Train Epoch: 5 [6000/7264 (82.58%)]\tLoss: 2.011116\n",
            "Train Epoch: 5 [6600/7264 (90.83%)]\tLoss: 1.993253\n",
            "Train Epoch: 5 [7200/7264 (99.09%)]\tLoss: 1.649469\n",
            "\n",
            "Test set: Average loss: 0.2672, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 6 [0/7264 (0.0%)]\tLoss: 1.787686\n",
            "Train Epoch: 6 [600/7264 (8.26%)]\tLoss: 1.487507\n",
            "Train Epoch: 6 [1200/7264 (16.52%)]\tLoss: 1.778988\n",
            "Train Epoch: 6 [1800/7264 (24.77%)]\tLoss: 2.075902\n",
            "Train Epoch: 6 [2400/7264 (33.03%)]\tLoss: 1.587805\n",
            "Train Epoch: 6 [3000/7264 (41.29%)]\tLoss: 1.614647\n",
            "Train Epoch: 6 [3600/7264 (49.55%)]\tLoss: 1.646765\n",
            "Train Epoch: 6 [4200/7264 (57.8%)]\tLoss: 1.669742\n",
            "Train Epoch: 6 [4800/7264 (66.06%)]\tLoss: 1.768733\n",
            "Train Epoch: 6 [5400/7264 (74.32%)]\tLoss: 1.738531\n",
            "Train Epoch: 6 [6000/7264 (82.58%)]\tLoss: 2.151584\n",
            "Train Epoch: 6 [6600/7264 (90.83%)]\tLoss: 1.693425\n",
            "Train Epoch: 6 [7200/7264 (99.09%)]\tLoss: 1.276439\n",
            "\n",
            "Test set: Average loss: 0.2654, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 7 [0/7264 (0.0%)]\tLoss: 1.624588\n",
            "Train Epoch: 7 [600/7264 (8.26%)]\tLoss: 1.578795\n",
            "Train Epoch: 7 [1200/7264 (16.52%)]\tLoss: 1.751323\n",
            "Train Epoch: 7 [1800/7264 (24.77%)]\tLoss: 1.436931\n",
            "Train Epoch: 7 [2400/7264 (33.03%)]\tLoss: 1.381039\n",
            "Train Epoch: 7 [3000/7264 (41.29%)]\tLoss: 1.713552\n",
            "Train Epoch: 7 [3600/7264 (49.55%)]\tLoss: 1.955256\n",
            "Train Epoch: 7 [4200/7264 (57.8%)]\tLoss: 1.97094\n",
            "Train Epoch: 7 [4800/7264 (66.06%)]\tLoss: 1.606986\n",
            "Train Epoch: 7 [5400/7264 (74.32%)]\tLoss: 1.764244\n",
            "Train Epoch: 7 [6000/7264 (82.58%)]\tLoss: 1.616184\n",
            "Train Epoch: 7 [6600/7264 (90.83%)]\tLoss: 2.390273\n",
            "Train Epoch: 7 [7200/7264 (99.09%)]\tLoss: 2.497942\n",
            "\n",
            "Test set: Average loss: 0.2652, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 8 [0/7264 (0.0%)]\tLoss: 1.663295\n",
            "Train Epoch: 8 [600/7264 (8.26%)]\tLoss: 1.809071\n",
            "Train Epoch: 8 [1200/7264 (16.52%)]\tLoss: 1.895542\n",
            "Train Epoch: 8 [1800/7264 (24.77%)]\tLoss: 1.465761\n",
            "Train Epoch: 8 [2400/7264 (33.03%)]\tLoss: 2.023774\n",
            "Train Epoch: 8 [3000/7264 (41.29%)]\tLoss: 1.658458\n",
            "Train Epoch: 8 [3600/7264 (49.55%)]\tLoss: 1.459967\n",
            "Train Epoch: 8 [4200/7264 (57.8%)]\tLoss: 1.489948\n",
            "Train Epoch: 8 [4800/7264 (66.06%)]\tLoss: 1.868269\n",
            "Train Epoch: 8 [5400/7264 (74.32%)]\tLoss: 1.479155\n",
            "Train Epoch: 8 [6000/7264 (82.58%)]\tLoss: 1.907557\n",
            "Train Epoch: 8 [6600/7264 (90.83%)]\tLoss: 1.75162\n",
            "Train Epoch: 8 [7200/7264 (99.09%)]\tLoss: 1.839649\n",
            "\n",
            "Test set: Average loss: 0.2648, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 9 [0/7264 (0.0%)]\tLoss: 2.014616\n",
            "Train Epoch: 9 [600/7264 (8.26%)]\tLoss: 1.606698\n",
            "Train Epoch: 9 [1200/7264 (16.52%)]\tLoss: 2.0519\n",
            "Train Epoch: 9 [1800/7264 (24.77%)]\tLoss: 1.605746\n",
            "Train Epoch: 9 [2400/7264 (33.03%)]\tLoss: 1.781376\n",
            "Train Epoch: 9 [3000/7264 (41.29%)]\tLoss: 2.112586\n",
            "Train Epoch: 9 [3600/7264 (49.55%)]\tLoss: 1.975636\n",
            "Train Epoch: 9 [4200/7264 (57.8%)]\tLoss: 1.657946\n",
            "Train Epoch: 9 [4800/7264 (66.06%)]\tLoss: 1.853072\n",
            "Train Epoch: 9 [5400/7264 (74.32%)]\tLoss: 1.580007\n",
            "Train Epoch: 9 [6000/7264 (82.58%)]\tLoss: 1.527923\n",
            "Train Epoch: 9 [6600/7264 (90.83%)]\tLoss: 1.740375\n",
            "Train Epoch: 9 [7200/7264 (99.09%)]\tLoss: 1.833786\n",
            "\n",
            "Test set: Average loss: 0.2642, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 10 [0/7264 (0.0%)]\tLoss: 1.389672\n",
            "Train Epoch: 10 [600/7264 (8.26%)]\tLoss: 2.011213\n",
            "Train Epoch: 10 [1200/7264 (16.52%)]\tLoss: 1.988082\n",
            "Train Epoch: 10 [1800/7264 (24.77%)]\tLoss: 1.906828\n",
            "Train Epoch: 10 [2400/7264 (33.03%)]\tLoss: 1.6188\n",
            "Train Epoch: 10 [3000/7264 (41.29%)]\tLoss: 1.686861\n",
            "Train Epoch: 10 [3600/7264 (49.55%)]\tLoss: 1.700703\n",
            "Train Epoch: 10 [4200/7264 (57.8%)]\tLoss: 1.658397\n",
            "Train Epoch: 10 [4800/7264 (66.06%)]\tLoss: 1.956281\n",
            "Train Epoch: 10 [5400/7264 (74.32%)]\tLoss: 1.719945\n",
            "Train Epoch: 10 [6000/7264 (82.58%)]\tLoss: 1.63119\n",
            "Train Epoch: 10 [6600/7264 (90.83%)]\tLoss: 1.750993\n",
            "Train Epoch: 10 [7200/7264 (99.09%)]\tLoss: 1.787976\n",
            "\n",
            "Test set: Average loss: 0.2639, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 11 [0/7264 (0.0%)]\tLoss: 2.12882\n",
            "Train Epoch: 11 [600/7264 (8.26%)]\tLoss: 1.350315\n",
            "Train Epoch: 11 [1200/7264 (16.52%)]\tLoss: 1.718732\n",
            "Train Epoch: 11 [1800/7264 (24.77%)]\tLoss: 1.516278\n",
            "Train Epoch: 11 [2400/7264 (33.03%)]\tLoss: 1.98314\n",
            "Train Epoch: 11 [3000/7264 (41.29%)]\tLoss: 1.876884\n",
            "Train Epoch: 11 [3600/7264 (49.55%)]\tLoss: 1.574102\n",
            "Train Epoch: 11 [4200/7264 (57.8%)]\tLoss: 1.330484\n",
            "Train Epoch: 11 [4800/7264 (66.06%)]\tLoss: 1.982206\n",
            "Train Epoch: 11 [5400/7264 (74.32%)]\tLoss: 1.594676\n",
            "Train Epoch: 11 [6000/7264 (82.58%)]\tLoss: 1.664853\n",
            "Train Epoch: 11 [6600/7264 (90.83%)]\tLoss: 1.834694\n",
            "Train Epoch: 11 [7200/7264 (99.09%)]\tLoss: 2.09078\n",
            "\n",
            "Test set: Average loss: 0.2633, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 12 [0/7264 (0.0%)]\tLoss: 1.98841\n",
            "Train Epoch: 12 [600/7264 (8.26%)]\tLoss: 1.792051\n",
            "Train Epoch: 12 [1200/7264 (16.52%)]\tLoss: 1.677384\n",
            "Train Epoch: 12 [1800/7264 (24.77%)]\tLoss: 2.038296\n",
            "Train Epoch: 12 [2400/7264 (33.03%)]\tLoss: 1.744478\n",
            "Train Epoch: 12 [3000/7264 (41.29%)]\tLoss: 1.659073\n",
            "Train Epoch: 12 [3600/7264 (49.55%)]\tLoss: 1.683514\n",
            "Train Epoch: 12 [4200/7264 (57.8%)]\tLoss: 1.928745\n",
            "Train Epoch: 12 [4800/7264 (66.06%)]\tLoss: 1.462834\n",
            "Train Epoch: 12 [5400/7264 (74.32%)]\tLoss: 1.697343\n",
            "Train Epoch: 12 [6000/7264 (82.58%)]\tLoss: 1.606018\n",
            "Train Epoch: 12 [6600/7264 (90.83%)]\tLoss: 1.740334\n",
            "Train Epoch: 12 [7200/7264 (99.09%)]\tLoss: 2.033002\n",
            "\n",
            "Test set: Average loss: 0.2630, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 13 [0/7264 (0.0%)]\tLoss: 1.10859\n",
            "Train Epoch: 13 [600/7264 (8.26%)]\tLoss: 1.798756\n",
            "Train Epoch: 13 [1200/7264 (16.52%)]\tLoss: 1.682808\n",
            "Train Epoch: 13 [1800/7264 (24.77%)]\tLoss: 1.825879\n",
            "Train Epoch: 13 [2400/7264 (33.03%)]\tLoss: 1.802153\n",
            "Train Epoch: 13 [3000/7264 (41.29%)]\tLoss: 1.788689\n",
            "Train Epoch: 13 [3600/7264 (49.55%)]\tLoss: 1.327292\n",
            "Train Epoch: 13 [4200/7264 (57.8%)]\tLoss: 1.730681\n",
            "Train Epoch: 13 [4800/7264 (66.06%)]\tLoss: 1.804393\n",
            "Train Epoch: 13 [5400/7264 (74.32%)]\tLoss: 1.423282\n",
            "Train Epoch: 13 [6000/7264 (82.58%)]\tLoss: 1.589522\n",
            "Train Epoch: 13 [6600/7264 (90.83%)]\tLoss: 1.870993\n",
            "Train Epoch: 13 [7200/7264 (99.09%)]\tLoss: 1.723206\n",
            "\n",
            "Test set: Average loss: 0.2626, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 14 [0/7264 (0.0%)]\tLoss: 1.469243\n",
            "Train Epoch: 14 [600/7264 (8.26%)]\tLoss: 1.880984\n",
            "Train Epoch: 14 [1200/7264 (16.52%)]\tLoss: 1.616863\n",
            "Train Epoch: 14 [1800/7264 (24.77%)]\tLoss: 1.594851\n",
            "Train Epoch: 14 [2400/7264 (33.03%)]\tLoss: 1.743154\n",
            "Train Epoch: 14 [3000/7264 (41.29%)]\tLoss: 2.089869\n",
            "Train Epoch: 14 [3600/7264 (49.55%)]\tLoss: 1.511316\n",
            "Train Epoch: 14 [4200/7264 (57.8%)]\tLoss: 1.77463\n",
            "Train Epoch: 14 [4800/7264 (66.06%)]\tLoss: 1.830241\n",
            "Train Epoch: 14 [5400/7264 (74.32%)]\tLoss: 1.672249\n",
            "Train Epoch: 14 [6000/7264 (82.58%)]\tLoss: 1.778058\n",
            "Train Epoch: 14 [6600/7264 (90.83%)]\tLoss: 1.906198\n",
            "Train Epoch: 14 [7200/7264 (99.09%)]\tLoss: 1.349578\n",
            "\n",
            "Test set: Average loss: 0.2624, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 15 [0/7264 (0.0%)]\tLoss: 1.387132\n",
            "Train Epoch: 15 [600/7264 (8.26%)]\tLoss: 1.419235\n",
            "Train Epoch: 15 [1200/7264 (16.52%)]\tLoss: 1.569646\n",
            "Train Epoch: 15 [1800/7264 (24.77%)]\tLoss: 1.705656\n",
            "Train Epoch: 15 [2400/7264 (33.03%)]\tLoss: 1.637922\n",
            "Train Epoch: 15 [3000/7264 (41.29%)]\tLoss: 1.862423\n",
            "Train Epoch: 15 [3600/7264 (49.55%)]\tLoss: 1.568525\n",
            "Train Epoch: 15 [4200/7264 (57.8%)]\tLoss: 1.649544\n",
            "Train Epoch: 15 [4800/7264 (66.06%)]\tLoss: 1.452518\n",
            "Train Epoch: 15 [5400/7264 (74.32%)]\tLoss: 1.653671\n",
            "Train Epoch: 15 [6000/7264 (82.58%)]\tLoss: 1.806948\n",
            "Train Epoch: 15 [6600/7264 (90.83%)]\tLoss: 1.349288\n",
            "Train Epoch: 15 [7200/7264 (99.09%)]\tLoss: 1.917926\n",
            "\n",
            "Test set: Average loss: 0.2623, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 16 [0/7264 (0.0%)]\tLoss: 1.93491\n",
            "Train Epoch: 16 [600/7264 (8.26%)]\tLoss: 1.758424\n",
            "Train Epoch: 16 [1200/7264 (16.52%)]\tLoss: 1.59518\n",
            "Train Epoch: 16 [1800/7264 (24.77%)]\tLoss: 1.74856\n",
            "Train Epoch: 16 [2400/7264 (33.03%)]\tLoss: 1.409121\n",
            "Train Epoch: 16 [3000/7264 (41.29%)]\tLoss: 1.486699\n",
            "Train Epoch: 16 [3600/7264 (49.55%)]\tLoss: 1.909854\n",
            "Train Epoch: 16 [4200/7264 (57.8%)]\tLoss: 1.393623\n",
            "Train Epoch: 16 [4800/7264 (66.06%)]\tLoss: 1.845134\n",
            "Train Epoch: 16 [5400/7264 (74.32%)]\tLoss: 1.435254\n",
            "Train Epoch: 16 [6000/7264 (82.58%)]\tLoss: 1.534152\n",
            "Train Epoch: 16 [6600/7264 (90.83%)]\tLoss: 1.506867\n",
            "Train Epoch: 16 [7200/7264 (99.09%)]\tLoss: 1.590475\n",
            "\n",
            "Test set: Average loss: 0.2621, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 17 [0/7264 (0.0%)]\tLoss: 1.72393\n",
            "Train Epoch: 17 [600/7264 (8.26%)]\tLoss: 1.797547\n",
            "Train Epoch: 17 [1200/7264 (16.52%)]\tLoss: 1.900638\n",
            "Train Epoch: 17 [1800/7264 (24.77%)]\tLoss: 1.397268\n",
            "Train Epoch: 17 [2400/7264 (33.03%)]\tLoss: 1.544325\n",
            "Train Epoch: 17 [3000/7264 (41.29%)]\tLoss: 1.874559\n",
            "Train Epoch: 17 [3600/7264 (49.55%)]\tLoss: 1.522022\n",
            "Train Epoch: 17 [4200/7264 (57.8%)]\tLoss: 1.36856\n",
            "Train Epoch: 17 [4800/7264 (66.06%)]\tLoss: 1.512122\n",
            "Train Epoch: 17 [5400/7264 (74.32%)]\tLoss: 1.723761\n",
            "Train Epoch: 17 [6000/7264 (82.58%)]\tLoss: 1.658341\n",
            "Train Epoch: 17 [6600/7264 (90.83%)]\tLoss: 1.739046\n",
            "Train Epoch: 17 [7200/7264 (99.09%)]\tLoss: 1.643809\n",
            "\n",
            "Test set: Average loss: 0.2619, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 18 [0/7264 (0.0%)]\tLoss: 1.505371\n",
            "Train Epoch: 18 [600/7264 (8.26%)]\tLoss: 1.703636\n",
            "Train Epoch: 18 [1200/7264 (16.52%)]\tLoss: 1.632052\n",
            "Train Epoch: 18 [1800/7264 (24.77%)]\tLoss: 1.556205\n",
            "Train Epoch: 18 [2400/7264 (33.03%)]\tLoss: 2.0073\n",
            "Train Epoch: 18 [3000/7264 (41.29%)]\tLoss: 1.738311\n",
            "Train Epoch: 18 [3600/7264 (49.55%)]\tLoss: 1.576232\n",
            "Train Epoch: 18 [4200/7264 (57.8%)]\tLoss: 2.087392\n",
            "Train Epoch: 18 [4800/7264 (66.06%)]\tLoss: 1.826346\n",
            "Train Epoch: 18 [5400/7264 (74.32%)]\tLoss: 1.639504\n",
            "Train Epoch: 18 [6000/7264 (82.58%)]\tLoss: 1.567258\n",
            "Train Epoch: 18 [6600/7264 (90.83%)]\tLoss: 1.740649\n",
            "Train Epoch: 18 [7200/7264 (99.09%)]\tLoss: 1.880288\n",
            "\n",
            "Test set: Average loss: 0.2616, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 19 [0/7264 (0.0%)]\tLoss: 1.520213\n",
            "Train Epoch: 19 [600/7264 (8.26%)]\tLoss: 1.634376\n",
            "Train Epoch: 19 [1200/7264 (16.52%)]\tLoss: 1.671555\n",
            "Train Epoch: 19 [1800/7264 (24.77%)]\tLoss: 2.046015\n",
            "Train Epoch: 19 [2400/7264 (33.03%)]\tLoss: 1.3104\n",
            "Train Epoch: 19 [3000/7264 (41.29%)]\tLoss: 1.68689\n",
            "Train Epoch: 19 [3600/7264 (49.55%)]\tLoss: 1.756826\n",
            "Train Epoch: 19 [4200/7264 (57.8%)]\tLoss: 1.490131\n",
            "Train Epoch: 19 [4800/7264 (66.06%)]\tLoss: 1.536146\n",
            "Train Epoch: 19 [5400/7264 (74.32%)]\tLoss: 1.541972\n",
            "Train Epoch: 19 [6000/7264 (82.58%)]\tLoss: 1.593973\n",
            "Train Epoch: 19 [6600/7264 (90.83%)]\tLoss: 1.613943\n",
            "Train Epoch: 19 [7200/7264 (99.09%)]\tLoss: 1.659226\n",
            "\n",
            "Test set: Average loss: 0.2615, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 20 [0/7264 (0.0%)]\tLoss: 1.833661\n",
            "Train Epoch: 20 [600/7264 (8.26%)]\tLoss: 1.875792\n",
            "Train Epoch: 20 [1200/7264 (16.52%)]\tLoss: 1.338807\n",
            "Train Epoch: 20 [1800/7264 (24.77%)]\tLoss: 1.573146\n",
            "Train Epoch: 20 [2400/7264 (33.03%)]\tLoss: 1.968479\n",
            "Train Epoch: 20 [3000/7264 (41.29%)]\tLoss: 1.588587\n",
            "Train Epoch: 20 [3600/7264 (49.55%)]\tLoss: 1.651203\n",
            "Train Epoch: 20 [4200/7264 (57.8%)]\tLoss: 1.545187\n",
            "Train Epoch: 20 [4800/7264 (66.06%)]\tLoss: 1.635499\n",
            "Train Epoch: 20 [5400/7264 (74.32%)]\tLoss: 1.890091\n",
            "Train Epoch: 20 [6000/7264 (82.58%)]\tLoss: 1.618456\n",
            "Train Epoch: 20 [6600/7264 (90.83%)]\tLoss: 1.561223\n",
            "Train Epoch: 20 [7200/7264 (99.09%)]\tLoss: 1.636899\n",
            "\n",
            "Test set: Average loss: 0.2613, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 21 [0/7264 (0.0%)]\tLoss: 1.535789\n",
            "Train Epoch: 21 [600/7264 (8.26%)]\tLoss: 1.636352\n",
            "Train Epoch: 21 [1200/7264 (16.52%)]\tLoss: 1.506978\n",
            "Train Epoch: 21 [1800/7264 (24.77%)]\tLoss: 1.410381\n",
            "Train Epoch: 21 [2400/7264 (33.03%)]\tLoss: 1.571475\n",
            "Train Epoch: 21 [3000/7264 (41.29%)]\tLoss: 1.546481\n",
            "Train Epoch: 21 [3600/7264 (49.55%)]\tLoss: 1.608928\n",
            "Train Epoch: 21 [4200/7264 (57.8%)]\tLoss: 1.868646\n",
            "Train Epoch: 21 [4800/7264 (66.06%)]\tLoss: 1.521751\n",
            "Train Epoch: 21 [5400/7264 (74.32%)]\tLoss: 1.605722\n",
            "Train Epoch: 21 [6000/7264 (82.58%)]\tLoss: 1.48114\n",
            "Train Epoch: 21 [6600/7264 (90.83%)]\tLoss: 1.678934\n",
            "Train Epoch: 21 [7200/7264 (99.09%)]\tLoss: 1.562483\n",
            "\n",
            "Test set: Average loss: 0.2615, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 22 [0/7264 (0.0%)]\tLoss: 1.637697\n",
            "Train Epoch: 22 [600/7264 (8.26%)]\tLoss: 1.434142\n",
            "Train Epoch: 22 [1200/7264 (16.52%)]\tLoss: 1.740678\n",
            "Train Epoch: 22 [1800/7264 (24.77%)]\tLoss: 1.38538\n",
            "Train Epoch: 22 [2400/7264 (33.03%)]\tLoss: 1.449044\n",
            "Train Epoch: 22 [3000/7264 (41.29%)]\tLoss: 1.667401\n",
            "Train Epoch: 22 [3600/7264 (49.55%)]\tLoss: 1.715795\n",
            "Train Epoch: 22 [4200/7264 (57.8%)]\tLoss: 1.710593\n",
            "Train Epoch: 22 [4800/7264 (66.06%)]\tLoss: 1.714696\n",
            "Train Epoch: 22 [5400/7264 (74.32%)]\tLoss: 1.517678\n",
            "Train Epoch: 22 [6000/7264 (82.58%)]\tLoss: 1.612123\n",
            "Train Epoch: 22 [6600/7264 (90.83%)]\tLoss: 1.576519\n",
            "Train Epoch: 22 [7200/7264 (99.09%)]\tLoss: 1.469581\n",
            "\n",
            "Test set: Average loss: 0.2612, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 23 [0/7264 (0.0%)]\tLoss: 1.693489\n",
            "Train Epoch: 23 [600/7264 (8.26%)]\tLoss: 1.686666\n",
            "Train Epoch: 23 [1200/7264 (16.52%)]\tLoss: 1.575585\n",
            "Train Epoch: 23 [1800/7264 (24.77%)]\tLoss: 1.822982\n",
            "Train Epoch: 23 [2400/7264 (33.03%)]\tLoss: 1.740003\n",
            "Train Epoch: 23 [3000/7264 (41.29%)]\tLoss: 1.707675\n",
            "Train Epoch: 23 [3600/7264 (49.55%)]\tLoss: 1.593698\n",
            "Train Epoch: 23 [4200/7264 (57.8%)]\tLoss: 1.770417\n",
            "Train Epoch: 23 [4800/7264 (66.06%)]\tLoss: 1.485755\n",
            "Train Epoch: 23 [5400/7264 (74.32%)]\tLoss: 1.703968\n",
            "Train Epoch: 23 [6000/7264 (82.58%)]\tLoss: 1.653382\n",
            "Train Epoch: 23 [6600/7264 (90.83%)]\tLoss: 2.022517\n",
            "Train Epoch: 23 [7200/7264 (99.09%)]\tLoss: 1.724188\n",
            "\n",
            "Test set: Average loss: 0.2613, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 24 [0/7264 (0.0%)]\tLoss: 1.746757\n",
            "Train Epoch: 24 [600/7264 (8.26%)]\tLoss: 1.593339\n",
            "Train Epoch: 24 [1200/7264 (16.52%)]\tLoss: 1.506321\n",
            "Train Epoch: 24 [1800/7264 (24.77%)]\tLoss: 1.462806\n",
            "Train Epoch: 24 [2400/7264 (33.03%)]\tLoss: 1.784482\n",
            "Train Epoch: 24 [3000/7264 (41.29%)]\tLoss: 1.424202\n",
            "Train Epoch: 24 [3600/7264 (49.55%)]\tLoss: 1.497849\n",
            "Train Epoch: 24 [4200/7264 (57.8%)]\tLoss: 1.434241\n",
            "Train Epoch: 24 [4800/7264 (66.06%)]\tLoss: 1.73901\n",
            "Train Epoch: 24 [5400/7264 (74.32%)]\tLoss: 1.461722\n",
            "Train Epoch: 24 [6000/7264 (82.58%)]\tLoss: 1.640105\n",
            "Train Epoch: 24 [6600/7264 (90.83%)]\tLoss: 1.486517\n",
            "Train Epoch: 24 [7200/7264 (99.09%)]\tLoss: 1.286308\n",
            "\n",
            "Test set: Average loss: 0.2610, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 25 [0/7264 (0.0%)]\tLoss: 1.565651\n",
            "Train Epoch: 25 [600/7264 (8.26%)]\tLoss: 1.657875\n",
            "Train Epoch: 25 [1200/7264 (16.52%)]\tLoss: 1.729187\n",
            "Train Epoch: 25 [1800/7264 (24.77%)]\tLoss: 1.466025\n",
            "Train Epoch: 25 [2400/7264 (33.03%)]\tLoss: 1.565995\n",
            "Train Epoch: 25 [3000/7264 (41.29%)]\tLoss: 1.590289\n",
            "Train Epoch: 25 [3600/7264 (49.55%)]\tLoss: 1.52648\n",
            "Train Epoch: 25 [4200/7264 (57.8%)]\tLoss: 1.85568\n",
            "Train Epoch: 25 [4800/7264 (66.06%)]\tLoss: 1.721957\n",
            "Train Epoch: 25 [5400/7264 (74.32%)]\tLoss: 1.567373\n",
            "Train Epoch: 25 [6000/7264 (82.58%)]\tLoss: 1.648188\n",
            "Train Epoch: 25 [6600/7264 (90.83%)]\tLoss: 1.67058\n",
            "Train Epoch: 25 [7200/7264 (99.09%)]\tLoss: 1.64714\n",
            "\n",
            "Test set: Average loss: 0.2609, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 26 [0/7264 (0.0%)]\tLoss: 1.774751\n",
            "Train Epoch: 26 [600/7264 (8.26%)]\tLoss: 1.586903\n",
            "Train Epoch: 26 [1200/7264 (16.52%)]\tLoss: 1.604251\n",
            "Train Epoch: 26 [1800/7264 (24.77%)]\tLoss: 1.421156\n",
            "Train Epoch: 26 [2400/7264 (33.03%)]\tLoss: 1.699036\n",
            "Train Epoch: 26 [3000/7264 (41.29%)]\tLoss: 1.686194\n",
            "Train Epoch: 26 [3600/7264 (49.55%)]\tLoss: 1.764915\n",
            "Train Epoch: 26 [4200/7264 (57.8%)]\tLoss: 1.622798\n",
            "Train Epoch: 26 [4800/7264 (66.06%)]\tLoss: 1.609885\n",
            "Train Epoch: 26 [5400/7264 (74.32%)]\tLoss: 1.656733\n",
            "Train Epoch: 26 [6000/7264 (82.58%)]\tLoss: 1.785906\n",
            "Train Epoch: 26 [6600/7264 (90.83%)]\tLoss: 1.842957\n",
            "Train Epoch: 26 [7200/7264 (99.09%)]\tLoss: 1.768236\n",
            "\n",
            "Test set: Average loss: 0.2609, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 27 [0/7264 (0.0%)]\tLoss: 1.514306\n",
            "Train Epoch: 27 [600/7264 (8.26%)]\tLoss: 1.601574\n",
            "Train Epoch: 27 [1200/7264 (16.52%)]\tLoss: 1.523052\n",
            "Train Epoch: 27 [1800/7264 (24.77%)]\tLoss: 1.552231\n",
            "Train Epoch: 27 [2400/7264 (33.03%)]\tLoss: 1.594511\n",
            "Train Epoch: 27 [3000/7264 (41.29%)]\tLoss: 1.56149\n",
            "Train Epoch: 27 [3600/7264 (49.55%)]\tLoss: 1.901389\n",
            "Train Epoch: 27 [4200/7264 (57.8%)]\tLoss: 1.359232\n",
            "Train Epoch: 27 [4800/7264 (66.06%)]\tLoss: 1.527896\n",
            "Train Epoch: 27 [5400/7264 (74.32%)]\tLoss: 1.369546\n",
            "Train Epoch: 27 [6000/7264 (82.58%)]\tLoss: 1.532582\n",
            "Train Epoch: 27 [6600/7264 (90.83%)]\tLoss: 1.647235\n",
            "Train Epoch: 27 [7200/7264 (99.09%)]\tLoss: 1.618106\n",
            "\n",
            "Test set: Average loss: 0.2607, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 28 [0/7264 (0.0%)]\tLoss: 1.663459\n",
            "Train Epoch: 28 [600/7264 (8.26%)]\tLoss: 1.61053\n",
            "Train Epoch: 28 [1200/7264 (16.52%)]\tLoss: 1.692085\n",
            "Train Epoch: 28 [1800/7264 (24.77%)]\tLoss: 1.578451\n",
            "Train Epoch: 28 [2400/7264 (33.03%)]\tLoss: 1.596684\n",
            "Train Epoch: 28 [3000/7264 (41.29%)]\tLoss: 1.820601\n",
            "Train Epoch: 28 [3600/7264 (49.55%)]\tLoss: 1.562034\n",
            "Train Epoch: 28 [4200/7264 (57.8%)]\tLoss: 1.623022\n",
            "Train Epoch: 28 [4800/7264 (66.06%)]\tLoss: 1.7121\n",
            "Train Epoch: 28 [5400/7264 (74.32%)]\tLoss: 1.431319\n",
            "Train Epoch: 28 [6000/7264 (82.58%)]\tLoss: 1.5228\n",
            "Train Epoch: 28 [6600/7264 (90.83%)]\tLoss: 1.675237\n",
            "Train Epoch: 28 [7200/7264 (99.09%)]\tLoss: 1.690047\n",
            "\n",
            "Test set: Average loss: 0.2606, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 29 [0/7264 (0.0%)]\tLoss: 1.523993\n",
            "Train Epoch: 29 [600/7264 (8.26%)]\tLoss: 1.554387\n",
            "Train Epoch: 29 [1200/7264 (16.52%)]\tLoss: 1.602984\n",
            "Train Epoch: 29 [1800/7264 (24.77%)]\tLoss: 1.705526\n",
            "Train Epoch: 29 [2400/7264 (33.03%)]\tLoss: 1.6151\n",
            "Train Epoch: 29 [3000/7264 (41.29%)]\tLoss: 1.644596\n",
            "Train Epoch: 29 [3600/7264 (49.55%)]\tLoss: 1.764522\n",
            "Train Epoch: 29 [4200/7264 (57.8%)]\tLoss: 1.572308\n",
            "Train Epoch: 29 [4800/7264 (66.06%)]\tLoss: 1.60042\n",
            "Train Epoch: 29 [5400/7264 (74.32%)]\tLoss: 1.717244\n",
            "Train Epoch: 29 [6000/7264 (82.58%)]\tLoss: 1.4472\n",
            "Train Epoch: 29 [6600/7264 (90.83%)]\tLoss: 1.551134\n",
            "Train Epoch: 29 [7200/7264 (99.09%)]\tLoss: 1.70863\n",
            "\n",
            "Test set: Average loss: 0.2605, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 30 [0/7264 (0.0%)]\tLoss: 1.617329\n",
            "Train Epoch: 30 [600/7264 (8.26%)]\tLoss: 1.789438\n",
            "Train Epoch: 30 [1200/7264 (16.52%)]\tLoss: 1.521819\n",
            "Train Epoch: 30 [1800/7264 (24.77%)]\tLoss: 1.570886\n",
            "Train Epoch: 30 [2400/7264 (33.03%)]\tLoss: 1.81127\n",
            "Train Epoch: 30 [3000/7264 (41.29%)]\tLoss: 1.592118\n",
            "Train Epoch: 30 [3600/7264 (49.55%)]\tLoss: 1.409956\n",
            "Train Epoch: 30 [4200/7264 (57.8%)]\tLoss: 1.531381\n",
            "Train Epoch: 30 [4800/7264 (66.06%)]\tLoss: 1.445403\n",
            "Train Epoch: 30 [5400/7264 (74.32%)]\tLoss: 1.522971\n",
            "Train Epoch: 30 [6000/7264 (82.58%)]\tLoss: 1.564068\n",
            "Train Epoch: 30 [6600/7264 (90.83%)]\tLoss: 1.587608\n",
            "Train Epoch: 30 [7200/7264 (99.09%)]\tLoss: 1.643049\n",
            "\n",
            "Test set: Average loss: 0.2604, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 31 [0/7264 (0.0%)]\tLoss: 1.550254\n",
            "Train Epoch: 31 [600/7264 (8.26%)]\tLoss: 1.489348\n",
            "Train Epoch: 31 [1200/7264 (16.52%)]\tLoss: 1.875356\n",
            "Train Epoch: 31 [1800/7264 (24.77%)]\tLoss: 1.430157\n",
            "Train Epoch: 31 [2400/7264 (33.03%)]\tLoss: 1.466023\n",
            "Train Epoch: 31 [3000/7264 (41.29%)]\tLoss: 1.815779\n",
            "Train Epoch: 31 [3600/7264 (49.55%)]\tLoss: 1.820406\n",
            "Train Epoch: 31 [4200/7264 (57.8%)]\tLoss: 1.776912\n",
            "Train Epoch: 31 [4800/7264 (66.06%)]\tLoss: 1.576558\n",
            "Train Epoch: 31 [5400/7264 (74.32%)]\tLoss: 1.53191\n",
            "Train Epoch: 31 [6000/7264 (82.58%)]\tLoss: 1.593438\n",
            "Train Epoch: 31 [6600/7264 (90.83%)]\tLoss: 1.548676\n",
            "Train Epoch: 31 [7200/7264 (99.09%)]\tLoss: 1.646855\n",
            "\n",
            "Test set: Average loss: 0.2604, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 32 [0/7264 (0.0%)]\tLoss: 1.719462\n",
            "Train Epoch: 32 [600/7264 (8.26%)]\tLoss: 1.389349\n",
            "Train Epoch: 32 [1200/7264 (16.52%)]\tLoss: 1.477248\n",
            "Train Epoch: 32 [1800/7264 (24.77%)]\tLoss: 1.53887\n",
            "Train Epoch: 32 [2400/7264 (33.03%)]\tLoss: 1.443458\n",
            "Train Epoch: 32 [3000/7264 (41.29%)]\tLoss: 1.366038\n",
            "Train Epoch: 32 [3600/7264 (49.55%)]\tLoss: 1.681733\n",
            "Train Epoch: 32 [4200/7264 (57.8%)]\tLoss: 1.720082\n",
            "Train Epoch: 32 [4800/7264 (66.06%)]\tLoss: 1.779011\n",
            "Train Epoch: 32 [5400/7264 (74.32%)]\tLoss: 1.805701\n",
            "Train Epoch: 32 [6000/7264 (82.58%)]\tLoss: 1.625003\n",
            "Train Epoch: 32 [6600/7264 (90.83%)]\tLoss: 1.396868\n",
            "Train Epoch: 32 [7200/7264 (99.09%)]\tLoss: 1.578501\n",
            "\n",
            "Test set: Average loss: 0.2603, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 33 [0/7264 (0.0%)]\tLoss: 1.728863\n",
            "Train Epoch: 33 [600/7264 (8.26%)]\tLoss: 1.708291\n",
            "Train Epoch: 33 [1200/7264 (16.52%)]\tLoss: 1.714548\n",
            "Train Epoch: 33 [1800/7264 (24.77%)]\tLoss: 1.422557\n",
            "Train Epoch: 33 [2400/7264 (33.03%)]\tLoss: 1.638504\n",
            "Train Epoch: 33 [3000/7264 (41.29%)]\tLoss: 1.829082\n",
            "Train Epoch: 33 [3600/7264 (49.55%)]\tLoss: 1.52199\n",
            "Train Epoch: 33 [4200/7264 (57.8%)]\tLoss: 1.81309\n",
            "Train Epoch: 33 [4800/7264 (66.06%)]\tLoss: 1.838838\n",
            "Train Epoch: 33 [5400/7264 (74.32%)]\tLoss: 1.796179\n",
            "Train Epoch: 33 [6000/7264 (82.58%)]\tLoss: 1.775838\n",
            "Train Epoch: 33 [6600/7264 (90.83%)]\tLoss: 1.383785\n",
            "Train Epoch: 33 [7200/7264 (99.09%)]\tLoss: 1.656645\n",
            "\n",
            "Test set: Average loss: 0.2603, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 34 [0/7264 (0.0%)]\tLoss: 1.51289\n",
            "Train Epoch: 34 [600/7264 (8.26%)]\tLoss: 1.641115\n",
            "Train Epoch: 34 [1200/7264 (16.52%)]\tLoss: 1.560381\n",
            "Train Epoch: 34 [1800/7264 (24.77%)]\tLoss: 1.681619\n",
            "Train Epoch: 34 [2400/7264 (33.03%)]\tLoss: 1.468353\n",
            "Train Epoch: 34 [3000/7264 (41.29%)]\tLoss: 1.715523\n",
            "Train Epoch: 34 [3600/7264 (49.55%)]\tLoss: 1.575406\n",
            "Train Epoch: 34 [4200/7264 (57.8%)]\tLoss: 1.667617\n",
            "Train Epoch: 34 [4800/7264 (66.06%)]\tLoss: 1.463746\n",
            "Train Epoch: 34 [5400/7264 (74.32%)]\tLoss: 1.76326\n",
            "Train Epoch: 34 [6000/7264 (82.58%)]\tLoss: 1.740209\n",
            "Train Epoch: 34 [6600/7264 (90.83%)]\tLoss: 1.407256\n",
            "Train Epoch: 34 [7200/7264 (99.09%)]\tLoss: 1.527589\n",
            "\n",
            "Test set: Average loss: 0.2602, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 35 [0/7264 (0.0%)]\tLoss: 1.625852\n",
            "Train Epoch: 35 [600/7264 (8.26%)]\tLoss: 1.795595\n",
            "Train Epoch: 35 [1200/7264 (16.52%)]\tLoss: 1.591586\n",
            "Train Epoch: 35 [1800/7264 (24.77%)]\tLoss: 1.525476\n",
            "Train Epoch: 35 [2400/7264 (33.03%)]\tLoss: 1.566489\n",
            "Train Epoch: 35 [3000/7264 (41.29%)]\tLoss: 1.605295\n",
            "Train Epoch: 35 [3600/7264 (49.55%)]\tLoss: 1.873648\n",
            "Train Epoch: 35 [4200/7264 (57.8%)]\tLoss: 1.507029\n",
            "Train Epoch: 35 [4800/7264 (66.06%)]\tLoss: 1.671189\n",
            "Train Epoch: 35 [5400/7264 (74.32%)]\tLoss: 1.542798\n",
            "Train Epoch: 35 [6000/7264 (82.58%)]\tLoss: 1.654081\n",
            "Train Epoch: 35 [6600/7264 (90.83%)]\tLoss: 1.731665\n",
            "Train Epoch: 35 [7200/7264 (99.09%)]\tLoss: 1.763025\n",
            "\n",
            "Test set: Average loss: 0.2602, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 36 [0/7264 (0.0%)]\tLoss: 1.411291\n",
            "Train Epoch: 36 [600/7264 (8.26%)]\tLoss: 1.677025\n",
            "Train Epoch: 36 [1200/7264 (16.52%)]\tLoss: 1.584986\n",
            "Train Epoch: 36 [1800/7264 (24.77%)]\tLoss: 1.389419\n",
            "Train Epoch: 36 [2400/7264 (33.03%)]\tLoss: 1.63061\n",
            "Train Epoch: 36 [3000/7264 (41.29%)]\tLoss: 1.621856\n",
            "Train Epoch: 36 [3600/7264 (49.55%)]\tLoss: 1.718303\n",
            "Train Epoch: 36 [4200/7264 (57.8%)]\tLoss: 1.694502\n",
            "Train Epoch: 36 [4800/7264 (66.06%)]\tLoss: 1.478888\n",
            "Train Epoch: 36 [5400/7264 (74.32%)]\tLoss: 1.637132\n",
            "Train Epoch: 36 [6000/7264 (82.58%)]\tLoss: 1.702262\n",
            "Train Epoch: 36 [6600/7264 (90.83%)]\tLoss: 1.569483\n",
            "Train Epoch: 36 [7200/7264 (99.09%)]\tLoss: 1.472879\n",
            "\n",
            "Test set: Average loss: 0.2601, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 37 [0/7264 (0.0%)]\tLoss: 1.628098\n",
            "Train Epoch: 37 [600/7264 (8.26%)]\tLoss: 1.456138\n",
            "Train Epoch: 37 [1200/7264 (16.52%)]\tLoss: 1.416518\n",
            "Train Epoch: 37 [1800/7264 (24.77%)]\tLoss: 1.80929\n",
            "Train Epoch: 37 [2400/7264 (33.03%)]\tLoss: 1.507132\n",
            "Train Epoch: 37 [3000/7264 (41.29%)]\tLoss: 1.618605\n",
            "Train Epoch: 37 [3600/7264 (49.55%)]\tLoss: 1.766999\n",
            "Train Epoch: 37 [4200/7264 (57.8%)]\tLoss: 1.700071\n",
            "Train Epoch: 37 [4800/7264 (66.06%)]\tLoss: 1.618026\n",
            "Train Epoch: 37 [5400/7264 (74.32%)]\tLoss: 1.439433\n",
            "Train Epoch: 37 [6000/7264 (82.58%)]\tLoss: 1.720523\n",
            "Train Epoch: 37 [6600/7264 (90.83%)]\tLoss: 1.76511\n",
            "Train Epoch: 37 [7200/7264 (99.09%)]\tLoss: 1.565728\n",
            "\n",
            "Test set: Average loss: 0.2601, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 38 [0/7264 (0.0%)]\tLoss: 1.668248\n",
            "Train Epoch: 38 [600/7264 (8.26%)]\tLoss: 1.597354\n",
            "Train Epoch: 38 [1200/7264 (16.52%)]\tLoss: 1.708202\n",
            "Train Epoch: 38 [1800/7264 (24.77%)]\tLoss: 1.760629\n",
            "Train Epoch: 38 [2400/7264 (33.03%)]\tLoss: 1.549485\n",
            "Train Epoch: 38 [3000/7264 (41.29%)]\tLoss: 1.531892\n",
            "Train Epoch: 38 [3600/7264 (49.55%)]\tLoss: 1.565789\n",
            "Train Epoch: 38 [4200/7264 (57.8%)]\tLoss: 1.796584\n",
            "Train Epoch: 38 [4800/7264 (66.06%)]\tLoss: 1.424682\n",
            "Train Epoch: 38 [5400/7264 (74.32%)]\tLoss: 1.563664\n",
            "Train Epoch: 38 [6000/7264 (82.58%)]\tLoss: 1.508664\n",
            "Train Epoch: 38 [6600/7264 (90.83%)]\tLoss: 1.77166\n",
            "Train Epoch: 38 [7200/7264 (99.09%)]\tLoss: 1.677604\n",
            "\n",
            "Test set: Average loss: 0.2601, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 39 [0/7264 (0.0%)]\tLoss: 1.565785\n",
            "Train Epoch: 39 [600/7264 (8.26%)]\tLoss: 1.502157\n",
            "Train Epoch: 39 [1200/7264 (16.52%)]\tLoss: 1.654402\n",
            "Train Epoch: 39 [1800/7264 (24.77%)]\tLoss: 1.708495\n",
            "Train Epoch: 39 [2400/7264 (33.03%)]\tLoss: 1.410246\n",
            "Train Epoch: 39 [3000/7264 (41.29%)]\tLoss: 1.665204\n",
            "Train Epoch: 39 [3600/7264 (49.55%)]\tLoss: 1.636395\n",
            "Train Epoch: 39 [4200/7264 (57.8%)]\tLoss: 1.646684\n",
            "Train Epoch: 39 [4800/7264 (66.06%)]\tLoss: 1.58216\n",
            "Train Epoch: 39 [5400/7264 (74.32%)]\tLoss: 1.600924\n",
            "Train Epoch: 39 [6000/7264 (82.58%)]\tLoss: 1.931732\n",
            "Train Epoch: 39 [6600/7264 (90.83%)]\tLoss: 1.690848\n",
            "Train Epoch: 39 [7200/7264 (99.09%)]\tLoss: 1.60116\n",
            "\n",
            "Test set: Average loss: 0.2601, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 40 [0/7264 (0.0%)]\tLoss: 1.791181\n",
            "Train Epoch: 40 [600/7264 (8.26%)]\tLoss: 1.466812\n",
            "Train Epoch: 40 [1200/7264 (16.52%)]\tLoss: 1.780509\n",
            "Train Epoch: 40 [1800/7264 (24.77%)]\tLoss: 1.482436\n",
            "Train Epoch: 40 [2400/7264 (33.03%)]\tLoss: 1.537846\n",
            "Train Epoch: 40 [3000/7264 (41.29%)]\tLoss: 1.967885\n",
            "Train Epoch: 40 [3600/7264 (49.55%)]\tLoss: 1.630919\n",
            "Train Epoch: 40 [4200/7264 (57.8%)]\tLoss: 1.470777\n",
            "Train Epoch: 40 [4800/7264 (66.06%)]\tLoss: 1.735508\n",
            "Train Epoch: 40 [5400/7264 (74.32%)]\tLoss: 1.437479\n",
            "Train Epoch: 40 [6000/7264 (82.58%)]\tLoss: 1.464994\n",
            "Train Epoch: 40 [6600/7264 (90.83%)]\tLoss: 1.629249\n",
            "Train Epoch: 40 [7200/7264 (99.09%)]\tLoss: 1.590391\n",
            "\n",
            "Test set: Average loss: 0.2600, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 41 [0/7264 (0.0%)]\tLoss: 1.563327\n",
            "Train Epoch: 41 [600/7264 (8.26%)]\tLoss: 1.74662\n",
            "Train Epoch: 41 [1200/7264 (16.52%)]\tLoss: 1.715532\n",
            "Train Epoch: 41 [1800/7264 (24.77%)]\tLoss: 1.540179\n",
            "Train Epoch: 41 [2400/7264 (33.03%)]\tLoss: 1.486785\n",
            "Train Epoch: 41 [3000/7264 (41.29%)]\tLoss: 1.536614\n",
            "Train Epoch: 41 [3600/7264 (49.55%)]\tLoss: 1.334577\n",
            "Train Epoch: 41 [4200/7264 (57.8%)]\tLoss: 1.750798\n",
            "Train Epoch: 41 [4800/7264 (66.06%)]\tLoss: 1.4343\n",
            "Train Epoch: 41 [5400/7264 (74.32%)]\tLoss: 1.579071\n",
            "Train Epoch: 41 [6000/7264 (82.58%)]\tLoss: 1.610852\n",
            "Train Epoch: 41 [6600/7264 (90.83%)]\tLoss: 1.499581\n",
            "Train Epoch: 41 [7200/7264 (99.09%)]\tLoss: 1.760621\n",
            "\n",
            "Test set: Average loss: 0.2601, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 42 [0/7264 (0.0%)]\tLoss: 1.67147\n",
            "Train Epoch: 42 [600/7264 (8.26%)]\tLoss: 1.593433\n",
            "Train Epoch: 42 [1200/7264 (16.52%)]\tLoss: 1.519589\n",
            "Train Epoch: 42 [1800/7264 (24.77%)]\tLoss: 1.515076\n",
            "Train Epoch: 42 [2400/7264 (33.03%)]\tLoss: 1.70405\n",
            "Train Epoch: 42 [3000/7264 (41.29%)]\tLoss: 1.761681\n",
            "Train Epoch: 42 [3600/7264 (49.55%)]\tLoss: 1.596931\n",
            "Train Epoch: 42 [4200/7264 (57.8%)]\tLoss: 1.603754\n",
            "Train Epoch: 42 [4800/7264 (66.06%)]\tLoss: 1.773943\n",
            "Train Epoch: 42 [5400/7264 (74.32%)]\tLoss: 1.587374\n",
            "Train Epoch: 42 [6000/7264 (82.58%)]\tLoss: 1.765005\n",
            "Train Epoch: 42 [6600/7264 (90.83%)]\tLoss: 1.571476\n",
            "Train Epoch: 42 [7200/7264 (99.09%)]\tLoss: 1.577514\n",
            "\n",
            "Test set: Average loss: 0.2601, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 43 [0/7264 (0.0%)]\tLoss: 1.504202\n",
            "Train Epoch: 43 [600/7264 (8.26%)]\tLoss: 1.627582\n",
            "Train Epoch: 43 [1200/7264 (16.52%)]\tLoss: 1.72372\n",
            "Train Epoch: 43 [1800/7264 (24.77%)]\tLoss: 1.768247\n",
            "Train Epoch: 43 [2400/7264 (33.03%)]\tLoss: 1.570356\n",
            "Train Epoch: 43 [3000/7264 (41.29%)]\tLoss: 1.456612\n",
            "Train Epoch: 43 [3600/7264 (49.55%)]\tLoss: 1.752397\n",
            "Train Epoch: 43 [4200/7264 (57.8%)]\tLoss: 1.808277\n",
            "Train Epoch: 43 [4800/7264 (66.06%)]\tLoss: 1.651702\n",
            "Train Epoch: 43 [5400/7264 (74.32%)]\tLoss: 1.708719\n",
            "Train Epoch: 43 [6000/7264 (82.58%)]\tLoss: 1.484935\n",
            "Train Epoch: 43 [6600/7264 (90.83%)]\tLoss: 1.545794\n",
            "Train Epoch: 43 [7200/7264 (99.09%)]\tLoss: 1.52699\n",
            "\n",
            "Test set: Average loss: 0.2599, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 44 [0/7264 (0.0%)]\tLoss: 1.683646\n",
            "Train Epoch: 44 [600/7264 (8.26%)]\tLoss: 1.57645\n",
            "Train Epoch: 44 [1200/7264 (16.52%)]\tLoss: 1.622843\n",
            "Train Epoch: 44 [1800/7264 (24.77%)]\tLoss: 1.499857\n",
            "Train Epoch: 44 [2400/7264 (33.03%)]\tLoss: 1.746178\n",
            "Train Epoch: 44 [3000/7264 (41.29%)]\tLoss: 1.634816\n",
            "Train Epoch: 44 [3600/7264 (49.55%)]\tLoss: 1.804561\n",
            "Train Epoch: 44 [4200/7264 (57.8%)]\tLoss: 1.726382\n",
            "Train Epoch: 44 [4800/7264 (66.06%)]\tLoss: 1.513826\n",
            "Train Epoch: 44 [5400/7264 (74.32%)]\tLoss: 1.587497\n",
            "Train Epoch: 44 [6000/7264 (82.58%)]\tLoss: 1.697411\n",
            "Train Epoch: 44 [6600/7264 (90.83%)]\tLoss: 1.77113\n",
            "Train Epoch: 44 [7200/7264 (99.09%)]\tLoss: 1.77504\n",
            "\n",
            "Test set: Average loss: 0.2599, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 45 [0/7264 (0.0%)]\tLoss: 1.549995\n",
            "Train Epoch: 45 [600/7264 (8.26%)]\tLoss: 1.49648\n",
            "Train Epoch: 45 [1200/7264 (16.52%)]\tLoss: 1.631912\n",
            "Train Epoch: 45 [1800/7264 (24.77%)]\tLoss: 1.629087\n",
            "Train Epoch: 45 [2400/7264 (33.03%)]\tLoss: 1.662976\n",
            "Train Epoch: 45 [3000/7264 (41.29%)]\tLoss: 1.518029\n",
            "Train Epoch: 45 [3600/7264 (49.55%)]\tLoss: 1.529547\n",
            "Train Epoch: 45 [4200/7264 (57.8%)]\tLoss: 1.642792\n",
            "Train Epoch: 45 [4800/7264 (66.06%)]\tLoss: 1.631839\n",
            "Train Epoch: 45 [5400/7264 (74.32%)]\tLoss: 1.761079\n",
            "Train Epoch: 45 [6000/7264 (82.58%)]\tLoss: 1.622059\n",
            "Train Epoch: 45 [6600/7264 (90.83%)]\tLoss: 1.44816\n",
            "Train Epoch: 45 [7200/7264 (99.09%)]\tLoss: 1.472521\n",
            "\n",
            "Test set: Average loss: 0.2599, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 46 [0/7264 (0.0%)]\tLoss: 1.437975\n",
            "Train Epoch: 46 [600/7264 (8.26%)]\tLoss: 1.567446\n",
            "Train Epoch: 46 [1200/7264 (16.52%)]\tLoss: 1.52445\n",
            "Train Epoch: 46 [1800/7264 (24.77%)]\tLoss: 1.628491\n",
            "Train Epoch: 46 [2400/7264 (33.03%)]\tLoss: 1.692059\n",
            "Train Epoch: 46 [3000/7264 (41.29%)]\tLoss: 1.626397\n",
            "Train Epoch: 46 [3600/7264 (49.55%)]\tLoss: 1.396343\n",
            "Train Epoch: 46 [4200/7264 (57.8%)]\tLoss: 1.636756\n",
            "Train Epoch: 46 [4800/7264 (66.06%)]\tLoss: 1.739107\n",
            "Train Epoch: 46 [5400/7264 (74.32%)]\tLoss: 1.640018\n",
            "Train Epoch: 46 [6000/7264 (82.58%)]\tLoss: 1.616441\n",
            "Train Epoch: 46 [6600/7264 (90.83%)]\tLoss: 1.535235\n",
            "Train Epoch: 46 [7200/7264 (99.09%)]\tLoss: 1.335349\n",
            "\n",
            "Test set: Average loss: 0.2600, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 47 [0/7264 (0.0%)]\tLoss: 1.603461\n",
            "Train Epoch: 47 [600/7264 (8.26%)]\tLoss: 1.790237\n",
            "Train Epoch: 47 [1200/7264 (16.52%)]\tLoss: 1.448188\n",
            "Train Epoch: 47 [1800/7264 (24.77%)]\tLoss: 1.521657\n",
            "Train Epoch: 47 [2400/7264 (33.03%)]\tLoss: 1.499634\n",
            "Train Epoch: 47 [3000/7264 (41.29%)]\tLoss: 1.578222\n",
            "Train Epoch: 47 [3600/7264 (49.55%)]\tLoss: 1.531901\n",
            "Train Epoch: 47 [4200/7264 (57.8%)]\tLoss: 1.662411\n",
            "Train Epoch: 47 [4800/7264 (66.06%)]\tLoss: 1.599681\n",
            "Train Epoch: 47 [5400/7264 (74.32%)]\tLoss: 1.642912\n",
            "Train Epoch: 47 [6000/7264 (82.58%)]\tLoss: 1.715653\n",
            "Train Epoch: 47 [6600/7264 (90.83%)]\tLoss: 1.553137\n",
            "Train Epoch: 47 [7200/7264 (99.09%)]\tLoss: 1.554873\n",
            "\n",
            "Test set: Average loss: 0.2599, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 48 [0/7264 (0.0%)]\tLoss: 1.572615\n",
            "Train Epoch: 48 [600/7264 (8.26%)]\tLoss: 1.591595\n",
            "Train Epoch: 48 [1200/7264 (16.52%)]\tLoss: 1.632643\n",
            "Train Epoch: 48 [1800/7264 (24.77%)]\tLoss: 1.440488\n",
            "Train Epoch: 48 [2400/7264 (33.03%)]\tLoss: 1.562397\n",
            "Train Epoch: 48 [3000/7264 (41.29%)]\tLoss: 1.734374\n",
            "Train Epoch: 48 [3600/7264 (49.55%)]\tLoss: 1.542974\n",
            "Train Epoch: 48 [4200/7264 (57.8%)]\tLoss: 1.517075\n",
            "Train Epoch: 48 [4800/7264 (66.06%)]\tLoss: 1.600112\n",
            "Train Epoch: 48 [5400/7264 (74.32%)]\tLoss: 1.683289\n",
            "Train Epoch: 48 [6000/7264 (82.58%)]\tLoss: 1.543878\n",
            "Train Epoch: 48 [6600/7264 (90.83%)]\tLoss: 1.458505\n",
            "Train Epoch: 48 [7200/7264 (99.09%)]\tLoss: 1.622673\n",
            "\n",
            "Test set: Average loss: 0.2598, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 49 [0/7264 (0.0%)]\tLoss: 1.594291\n",
            "Train Epoch: 49 [600/7264 (8.26%)]\tLoss: 1.605688\n",
            "Train Epoch: 49 [1200/7264 (16.52%)]\tLoss: 1.779807\n",
            "Train Epoch: 49 [1800/7264 (24.77%)]\tLoss: 1.601493\n",
            "Train Epoch: 49 [2400/7264 (33.03%)]\tLoss: 1.562838\n",
            "Train Epoch: 49 [3000/7264 (41.29%)]\tLoss: 1.631899\n",
            "Train Epoch: 49 [3600/7264 (49.55%)]\tLoss: 1.573194\n",
            "Train Epoch: 49 [4200/7264 (57.8%)]\tLoss: 1.487337\n",
            "Train Epoch: 49 [4800/7264 (66.06%)]\tLoss: 1.651323\n",
            "Train Epoch: 49 [5400/7264 (74.32%)]\tLoss: 1.528559\n",
            "Train Epoch: 49 [6000/7264 (82.58%)]\tLoss: 1.39825\n",
            "Train Epoch: 49 [6600/7264 (90.83%)]\tLoss: 1.564257\n",
            "Train Epoch: 49 [7200/7264 (99.09%)]\tLoss: 1.698465\n",
            "\n",
            "Test set: Average loss: 0.2598, Accuracy: 806/2422 (33%)\n",
            "\n",
            "Train Epoch: 50 [0/7264 (0.0%)]\tLoss: 1.628053\n",
            "Train Epoch: 50 [600/7264 (8.26%)]\tLoss: 1.467216\n",
            "Train Epoch: 50 [1200/7264 (16.52%)]\tLoss: 1.885236\n",
            "Train Epoch: 50 [1800/7264 (24.77%)]\tLoss: 1.566304\n",
            "Train Epoch: 50 [2400/7264 (33.03%)]\tLoss: 1.740215\n",
            "Train Epoch: 50 [3000/7264 (41.29%)]\tLoss: 1.775606\n",
            "Train Epoch: 50 [3600/7264 (49.55%)]\tLoss: 1.606642\n",
            "Train Epoch: 50 [4200/7264 (57.8%)]\tLoss: 1.647086\n",
            "Train Epoch: 50 [4800/7264 (66.06%)]\tLoss: 1.666945\n",
            "Train Epoch: 50 [5400/7264 (74.32%)]\tLoss: 1.550749\n",
            "Train Epoch: 50 [6000/7264 (82.58%)]\tLoss: 1.704062\n",
            "Train Epoch: 50 [6600/7264 (90.83%)]\tLoss: 1.658934\n",
            "Train Epoch: 50 [7200/7264 (99.09%)]\tLoss: 1.588423\n",
            "\n",
            "Test set: Average loss: 0.2598, Accuracy: 806/2422 (33%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HoAz4db3Tuz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}